{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow == 2.5.0\n",
      "Converting HD5 to Protobuf...\n",
      "Training model: ../results/dnn-100-base/model-final.h5\n",
      "--------------------------------------------------\n",
      "Frozen model layers: \n",
      "x\n",
      "sequential/dense/MatMul/ReadVariableOp/resource\n",
      "sequential/dense/MatMul/ReadVariableOp\n",
      "sequential/dense/MatMul\n",
      "sequential/dense/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense/BiasAdd/ReadVariableOp\n",
      "sequential/dense/BiasAdd\n",
      "sequential/dense/Relu\n",
      "sequential/dense_1/MatMul/ReadVariableOp/resource\n",
      "sequential/dense_1/MatMul/ReadVariableOp\n",
      "sequential/dense_1/MatMul\n",
      "sequential/dense_1/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense_1/BiasAdd/ReadVariableOp\n",
      "sequential/dense_1/BiasAdd\n",
      "sequential/dense_1/Relu\n",
      "sequential/dense_2/MatMul/ReadVariableOp/resource\n",
      "sequential/dense_2/MatMul/ReadVariableOp\n",
      "sequential/dense_2/MatMul\n",
      "sequential/dense_2/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense_2/BiasAdd/ReadVariableOp\n",
      "sequential/dense_2/BiasAdd\n",
      "sequential/dense_2/Relu\n",
      "sequential/dense_3/MatMul/ReadVariableOp/resource\n",
      "sequential/dense_3/MatMul/ReadVariableOp\n",
      "sequential/dense_3/MatMul\n",
      "sequential/dense_3/BiasAdd/ReadVariableOp/resource\n",
      "sequential/dense_3/BiasAdd/ReadVariableOp\n",
      "sequential/dense_3/BiasAdd\n",
      "sequential/dense_3/Softmax\n",
      "Identity\n",
      "--------------------------------------------------\n",
      "Frozen model inputs: \n",
      "[<tf.Tensor 'x:0' shape=(None, 11) dtype=float32>]\n",
      "Frozen model outputs: \n",
      "[<tf.Tensor 'Identity:0' shape=(None, 8) dtype=float32>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 21:02:18.588945: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-07-17 21:02:18.589050: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-07-17 21:02:18.590078: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "print('Tensorflow ==', tf.__version__)\n",
    "trained_model = '../results/dnn-100-base/model-final.h5'\n",
    "proto_model = '../results/dnn-100-base/model-protobuf'\n",
    "\n",
    "def convert_h5_protobuf(trained_model):\n",
    "    \"\"\" freeze your Keras model and save it as protobuf\n",
    "    Args:\n",
    "        trained_model (_type_): keras model\n",
    "    \"\"\"\n",
    "    # https://medium.com/@sebastingarcaacosta/how-to-export-a-tensorflow-2-x-keras-model-to-a-frozen-and-optimized-graph-39740846d9eb\n",
    "    print(\"Converting HD5 to Protobuf...\")\n",
    "    print(\"Training model:\", trained_model)\n",
    "    model = load_model(trained_model)\n",
    "    \n",
    "    # Convert Keras model to ConcreteFunction\n",
    "    full_model = tf.function(lambda x: model(x))\n",
    "    full_model = full_model.get_concrete_function(\n",
    "        tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
    "\n",
    "    # Get frozen ConcreteFunction\n",
    "    frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "    frozen_func.graph.as_graph_def()\n",
    "\n",
    "    layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model layers: \")\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model inputs: \")\n",
    "    print(frozen_func.inputs)\n",
    "    print(\"Frozen model outputs: \")\n",
    "    print(frozen_func.outputs)\n",
    "\n",
    "    # Save frozen graph from frozen ConcreteFunction to hard drive\n",
    "    tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                    logdir=Path(trained_model).parent,\n",
    "                    name=\"frozen_graph.pb\",\n",
    "                    as_text=False)\n",
    "\n",
    "    tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                    logdir=Path(trained_model).parent,\n",
    "                    name=\"frozen_graph.pbtext\",\n",
    "                    as_text=True)\n",
    "\n",
    "convert_h5_protobuf(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'a': 'a1', 'b': 'b1'}, {'a': 'a2', 'b': 'b2'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a':'a1', 'b':'b1'}\n",
    "b = {'a':'a2', 'b':'b2'}\n",
    "c = (a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'a1', 'b': 'b1'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(c)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "c = \"({'a': 'a1', 'b': 'b1'}, {'a': 'a2', 'b': 'b2'})\"\n",
    "type(eval(c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('envisec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4af36f3ca596f5e8cc36ab3ac42c172155e6daf6ffe02a489c4457447e26849d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
